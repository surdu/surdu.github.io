I"y<p>What is Shazam, you may ask ? Let‚Äôs say you‚Äôre in a bar, and they play a song that you like and you don‚Äôt know its name ? Shazam can help you find out what is the name of that song.</p>

<p>What Shazam does, it lets you record up to 15 seconds of the song you are hearing and then it will tell you everything you want to know about that song: the artist, the name of the song, the album, offer you links to YouTube, to buy the song on iTunes, you name it.</p>

<p>Shazam was first offered in UK as a phone service over the GSM network, but now it‚Äôs available world-wide on smart phones. But this is not the wow part of the app. What is the most amazing thing, is the conditions in which it can detect the song it ‚Äúhears‚Äù: it can detect the song recorded in heavy background noise conditions (like a crowded bar, as I initially mentioned) and even when the recorded sound quality is very low (it can run over cellular phone network). It is so amazing, that it can distinguish a songs when 2 songs are playing simultaneously or when the song is in the background of a radio DJ.</p>

<p>So, how does it manage to do this? <em>Avery Li-Chun Wang</em>, chief scientist and co-founder of Shazam, published <a href="http://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">a paper that explains just that</a>. In a few words, it has a database of song fingerprints generated out of their spectrogram. When you record a sample with their app, they will generate a fingerprint for the recorded sample in the same way they did for all the songs in their database. After that they will try to find a match in their database for the sample.</p>

<p>In the next lines I will try to explain in simple terms what I understood from that paper.</p>

<h3 id="how-to-fingerprint-a-song">How to fingerprint a song</h3>

<p>First they generate a <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a> for the song. The spectrogram is a 3 dimensions graph. On the horizontal (<code class="highlighter-rouge">X</code>) axis, you have the time. On the vertical (<code class="highlighter-rouge">Y</code>) axis you have the frequency. The third dimension is represented by color intensity and it denotes the amplitude of a certain frequency.</p>

<p>Basically, a dot on the graph will represent the volume of a certain sound at a certain time in the song. A darker point means that the specific sound is louder than a lighter point.</p>

<p>Storing the full song in the database will occupy an enormous amount of space, considering that the Shazam database has more than 8 million songs. So instead, they will store only the intense sounds in the song, the time when they appear in the song and at which frequency.</p>

<p>So a spectrogram for a song will be transformed from this:</p>

<p><img src="/assets/images/shazam/1.png" alt="The initial spectrogram" /></p>

<p>into this:</p>

<p><img src="/assets/images/shazam/2.png" alt="The simplified spectrogram" /></p>

<p>Note that the darker spots in the spectrogram match the crosses in the second image.</p>

<p>To store this in the database in a way in which is efficient to search for a match (easy to index), they choose some of the points from within the simplified spectrogram, called <em>anchor points</em> and zones in the vicinity of them, called <em>target zone</em>.</p>

<p><img src="/assets/images/shazam/3.png" alt="Pairing the anchor point with points in a target zone" /></p>

<p>Now, for each point in the target zone, they will create a <a href="https://en.wikipedia.org/wiki/Hash_function">hash</a> that will be the aggregation of the following: the frequency at which the anchor point is located (<code class="highlighter-rouge">f1</code>) + the frequency at which the point in the target zone is located (<code class="highlighter-rouge">f2</code>)+ the time difference between the time when the point in the target zone is located in the song (<code class="highlighter-rouge">t2</code>) and the time when the anchor point is located in the song <code class="highlighter-rouge">(t1) + t1</code>. To simplify: <code class="highlighter-rouge">hash = (f1+f2+(t2-t1))+t1</code></p>

<p><img src="/assets/images/shazam/4.png" alt="How the hash is calculated" /></p>

<p>After this, they will store each hash generated like this in the database.</p>

<h3 id="detecting-the-song">Detecting the song</h3>

<p>They first repeat the same fingerprinting also to the recorded sample. Each hash generated from the sample sound, will be searched for a match in the database.</p>

<p>If a match is found you will have the time of the hash from the sample (<code class="highlighter-rouge">th1</code>), the time of the hash from the song in the database (<code class="highlighter-rouge">th2</code>) and implicitly the ID of the song for which the hash matched. Basically, <code class="highlighter-rouge">th1</code> is the time since the beginning of the sample until the time of the sample hash and <code class="highlighter-rouge">th2</code> is the time since the beginning of the song and the time of the song hash.</p>

<p>Now, they will draw a new graph called scatter graph. The graph will have on the horizontal axis (X) the time of the song in the database and on the vertical axis (Y) the time of the recorded sample. On the X axis we will mark <code class="highlighter-rouge">th2</code> and on the Y axis we will mark <code class="highlighter-rouge">th1</code>. The point of intersection of the two occurrence times (<code class="highlighter-rouge">th1</code> and <code class="highlighter-rouge">th2</code>) will be marked with a small circle.</p>

<p>The magic happens now: if the graph will contain a lot of pairs of <code class="highlighter-rouge">th1</code>‚Äòs and <code class="highlighter-rouge">th2</code>‚Äòs from the same song, a diagonal line will form. The idea behind the formation of that line is simple: the rate at which the peaks (the small crosses from the simplified spectrogram) in the database song appear will be the same rate in which the peaks appear in the recorded sample, so if you pair these times, the coordinates on the scatter graph will grow constantly (to the right-top of the graph) as the time passes on both axes.</p>

<p>Here is how a scatter graph will look for a non-matching run</p>

<p><img src="/assets/images/shazam/plot_bad.png" alt="Scatter graph of a non-matching run" /></p>

<p>versus how it will look for a matching run</p>

<p><img src="/assets/images/shazam/plot_ok.png" alt="Scatter graph of a matching run" /></p>

<p>Finally, they will calculate a difference between <code class="highlighter-rouge">th2</code> and <code class="highlighter-rouge">th1</code> (<code class="highlighter-rouge">dth</code>) and they will plot it in a <a href="https://en.wikipedia.org/wiki/Histogram">histogram</a>. If there is a match in the graph plotted, then there will be a lot of <code class="highlighter-rouge">dth</code>s with the same value, because, basically, subtracting the <code class="highlighter-rouge">th2</code> from <code class="highlighter-rouge">th1</code> will give the offset from where the sample was recorded (the difference between a point in the original song and the same point in the recorded sample). This will result in a peak within the histogram, which will confirm a match.</p>

<p>Here is how a histogram for a non-matching run will look like</p>

<p><img src="/assets/images/shazam/his_bad.png" alt="Histogram of a non-matching run" /></p>

<p>versus a histogram for a matching run</p>

<p><img src="/assets/images/shazam/his_ok.png" alt="Histogram of a matching run" /></p>

<p>That‚Äôs pretty much all the info I could get from the paper. If I missed something or you have other interesting facts about this, tell us in the comments.</p>

<p>Hope it helps üòâ</p>
:ET